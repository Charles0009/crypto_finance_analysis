{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code for the centralisation of the BurnieYilmaz process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import os \n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/charl/Documents/perso/crypto_finance_anlysis/BurnieYilmazRS19\n",
      "Load Data\n",
      "TERMS-RESTRICTED SUBMISSIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/charles/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/charles/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charles/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/charles/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/charles/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "working_dir = str(os.getcwd())\n",
    "print(working_dir)\n",
    "# Insert the path of modules folder\n",
    "\n",
    "try : \n",
    "\n",
    "    sys.path.insert(0, working_dir+'/BurnieYilmazRS19/' )\n",
    "    sys.path.insert(0, working_dir+'/BurnieYilmazRS19/dataPrep/VADER/' )\n",
    "    \n",
    "    from GenerateWordFreqResults import get_word_freq_results_csv\n",
    "    from VADER import plot_vader_values\n",
    "    from VADER import get_list_of_words_of_interest\n",
    "    from VADER_terms import get_vader_terms_csv\n",
    "\n",
    "except ModuleNotFoundError :\n",
    "    try:\n",
    "        sys.path.insert(0, working_dir+'/crypto_finance_anlysis/BurnieYilmazRS19/' )\n",
    "        sys.path.insert(0, working_dir+'/crypto_finance_anlysis/BurnieYilmazRS19/dataPrep/VADER/' )\n",
    "\n",
    "        from GenerateWordFreqResults import get_word_freq_results_csv\n",
    "        from VADER import plot_vader_values\n",
    "        from VADER import get_list_of_words_of_interest\n",
    "        from VADER_terms import get_vader_terms_csv\n",
    "        \n",
    "    except ModuleNotFoundError :\n",
    "        sys.path.insert(0, working_dir+'/' )\n",
    "\n",
    "        from GenerateWordFreqResults import get_word_freq_results_csv\n",
    "        from VADER import plot_vader_values\n",
    "        sys.path.insert(0, working_dir+'/dataPrep/VADER/' )\n",
    "        from VADER import get_list_of_words_of_interest\n",
    "        from VADER_terms import get_vader_terms_csv\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose conditions on variables \n",
    "\n",
    "- crypto_couple : choose the crypto couple you want to study (eg. 'BNBUSDT')\n",
    "- start_date_epoch : choose the start date of the study ( epoch format eg. 1650204350 )\n",
    "- end_date_epoch : choose the finish date of the study ( epoch format eg. 1650204350 )\n",
    "- subreddit_name : choose the subreddit you want to study (eg. 'CryptoCurrencies')\n",
    "- time_interval : choose the time interval you want to base your study on (eg. '3days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_couple = 'BNBUSDT'\n",
    "start_date_epoch =  1648771200\n",
    "end_date_epoch = 1659312000\n",
    "subreddit_name = 'CryptoCurrencies'\n",
    "time_interval= '3days'\n",
    "\n",
    "# filepath = get_word_freq_results_csv(crypto_couple, start_date_epoch, end_date_epoch, subreddit_name, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-17 16:05:50\n",
      "2022-06-17 16:05:50\n"
     ]
    }
   ],
   "source": [
    "time = datetime.fromtimestamp(1650204350)\n",
    "print(time)\n",
    "time = datetime.fromtimestamp(1655474750)\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add values to the vader term extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/charl/Documents/perso/crypto_finance_anlysis/BurnieYilmazRS19\n",
      "len list of relevant numerically terms :  0\n",
      "[]\n",
      "Submissions data loaded -  2023-04-01 03:01:23.529867\n",
      "REMOVE SUBMISSIONS BLANK AFTER PROCESSING\n",
      "Counting labels for each term\n",
      "path for saving vader file :/mnt/c/Users/charl/Documents/perso/crypto_finance_anlysis/BurnieYilmazRS19/dataPrep/VADER/vader_BNBUSDT_CryptoCurrencies_1650204350_1655474750.csv\n",
      "/mnt/c/Users/charl/Documents/perso/crypto_finance_anlysis/BurnieYilmazRS19\n",
      "crypto_couple :  BNBUSDT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EpochDate</th>\n",
       "      <th>mean_daily_price</th>\n",
       "      <th>no_submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650204350</td>\n",
       "      <td>411.75</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1650290750</td>\n",
       "      <td>411.75</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EpochDate  mean_daily_price  no_submissions\n",
       "0  1650204350            411.75              29\n",
       "1  1650290750            411.75              38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_pkl_data= working_dir+'/dataPrep/REDDIT/data/extracting/CryptoCurrencies_2022-04-17_2022-06-17.pkl'\n",
    "# path_to_pkl_data= working_dir+'/dataPrep/REDDIT/data/extracting/CryptoCurrencies_2021-02-01_2022-02-01.pkl'\n",
    "\n",
    "\n",
    "path_to_pkl_data1= working_dir+'/dataPrep/REDDIT/data/processing/tokenFreq/CryptoCurrencies_2022-04-17_2022-06-17.pkl'\n",
    "# path_to_pkl_data1= working_dir+'/dataPrep/REDDIT/data/processing/tokenFreq/CryptoCurrencies_2021-02-01_2022-02-01.pkl'\n",
    "\n",
    "print(working_dir)\n",
    "start_date_epoch = 1650204350\n",
    "end_date_epoch = 1655474750\n",
    "# start_date_epoch = 1612197402\n",
    "# end_date_epoch = 1643733402\n",
    "# path_to_pkl_data= filepath\n",
    "\n",
    "interval_in_seconds = 86400\n",
    "\n",
    "start_date = start_date_epoch\n",
    "end_date = end_date_epoch\n",
    "liste_timing_infos = list(range(start_date, end_date, interval_in_seconds))\n",
    "\n",
    "liste_of_words = get_list_of_words_of_interest(path_to_pkl_data1, threshold_num_submissions = 500)\n",
    "print(liste_of_words)\n",
    "file_path_csv_vader = get_vader_terms_csv(path_to_pkl_data, liste_of_words, liste_timing_infos, crypto_couple, subreddit_name, start_date_epoch, end_date_epoch)\n",
    "# file_path_csv_vader = working_dir+'/dataPrep/VADER/vader_BNBUSDT_CryptoCurrencies_1650204350_1655474750.csv'\n",
    "# liste_of_words = [\"tax\", \"ban\", \"bitcoin\"]\n",
    "df = plot_vader_values(file_path_csv_vader, liste_of_words,crypto_couple, subreddit_name, start_date_epoch, end_date_epoch,path_to_pkl_data1, plot_or_not = False, study_window = 6)\n",
    "\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation study between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EpochDate</th>\n",
       "      <th>mean_daily_price</th>\n",
       "      <th>no_submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650204350</td>\n",
       "      <td>411.75</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1650290750</td>\n",
       "      <td>411.75</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EpochDate  mean_daily_price  no_submissions\n",
       "0  1650204350            411.75              29\n",
       "1  1650290750            411.75              38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//////\n",
      "sorted_term_analysis_by_p_values_pos  ['no_submissions']\n",
      "//////\n",
      "values_of_tests_for_major_element  no_submissions      {'pearsonr': PearsonRResult(statistic=0.10289080114479725, pvalue=0.40018142424460357), 'spearmanr': SpearmanrResult(correlation=0.1259639652357788, pvalue=0.3023838281605997), 'kendalltau': KendalltauResult(correlation=0.09514504382824869, pvalue=0.2558172120757556)}\n"
     ]
    }
   ],
   "source": [
    "# from scipy.stats.stats import pearsonr\n",
    "# from scipy.stats.stats import spearmanr\n",
    "# from scipy.stats.stats import kendalltau\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "# from pandas import corr\n",
    "warnings.simplefilter(action='ignore', category=stats.ConstantInputWarning())\n",
    "\n",
    "# df1 = df[['EpochDate','Open','tax', 'ban', 'bitcoin','tax_POS_RATIO', 'tax_NEG_RATIO', 'bitcoin_POS_RATIO', 'bitcoin_NEG_RATIO', 'ban_POS_RATIO', 'ban_NEG_RATIO']]\n",
    "df1 = df\n",
    "dic_of_correl_results = defaultdict(dict)\n",
    "list_of_values_pval_pos =[]\n",
    "list_of_values_pval_neg =[]\n",
    "\n",
    "display(df1.head(2))\n",
    "df1 = df1.dropna(axis=0)\n",
    "\n",
    "for column in df1.columns:\n",
    "    if column == 'EpochDate':\n",
    "        continue\n",
    "    if column == 'mean_daily_price':\n",
    "        continue   \n",
    "    df2 = df[['mean_daily_price',column]]\n",
    "    df2 = df2.dropna(axis=0)\n",
    "    if df2.empty:\n",
    "        continue\n",
    "    \n",
    "    if (df2[column] == 0).all():\n",
    "        continue\n",
    "\n",
    "    # display(df2.head(2))\n",
    "\n",
    "    dic_of_correl_results[column]['pearsonr'] = stats.pearsonr(df2['mean_daily_price'], df2[column])\n",
    "    dic_of_correl_results[column]['spearmanr'] = stats.spearmanr(df2['mean_daily_price'], df2[column])\n",
    "    dic_of_correl_results[column]['kendalltau'] = stats.kendalltau(df2['mean_daily_price'], df2[column])\n",
    "    # dic_of_correl_results[column]['correlation_pandas'] = df2['mean_daily_price'].corr(df2[column])\n",
    "\n",
    "    if (dic_of_correl_results[column]['pearsonr'].pvalue) <=0:\n",
    "        list_of_values_pval_neg.append(column)\n",
    "    else:\n",
    "        list_of_values_pval_pos.append(column)\n",
    "\n",
    "# sorted_term_analysis_by_p_values = sorted(dic_of_correl_results.items(), key=lambda x:x[1])\n",
    "sorted_term_analysis_by_p_values_pos = sorted(list_of_values_pval_pos, key=lambda x: (dic_of_correl_results[x]['pearsonr'].pvalue, dic_of_correl_results[x]['spearmanr'].pvalue, dic_of_correl_results[x]['kendalltau'].pvalue), reverse=True)\n",
    "sorted_term_analysis_by_p_values_neg = sorted(list_of_values_pval_neg, key=lambda x: (dic_of_correl_results[x]['pearsonr'].pvalue, dic_of_correl_results[x]['spearmanr'].pvalue, dic_of_correl_results[x]['kendalltau'].pvalue))\n",
    "\n",
    "print(\"//////\")\n",
    "print(\"sorted_term_analysis_by_p_values_pos \", sorted_term_analysis_by_p_values_pos)\n",
    "# print(\"sorted_term_analysis_by_p_values_neg \", sorted_term_analysis_by_p_values_neg)\n",
    "print(\"//////\")\n",
    "\n",
    "\n",
    "major_element = sorted_term_analysis_by_p_values_pos[-1]\n",
    "values_of_tests_for_major_element = dic_of_correl_results[major_element]\n",
    "print(\"values_of_tests_for_major_element \",major_element ,\"    \", values_of_tests_for_major_element)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acce2ff996a6009c7246ec4a393389c98bfca356a70d70ae03325859b3002493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
